## 集成学习

### 主要思想

如果训练多个分类器，当输入一个样本，让这多个分类器分别做分类，之后做表决投票，采纳过半数的分类结果，这样能否让模型的结果变得更好呢？

如果这若干个分类器的错误率相互独立，则预测的错误率能指数下降。但是现实中这是不可能的，因为训练集本身就不相互独立。

根据个体学习器的生成方式，集成学习方法有两大类：1> 个体学习器之间<font color=red>有强依赖关系</font>，必须串行生成的序列化方法，代表方法是Boosting；另一种是个体学习器之间<font color=red>不存在强依赖关系</font>，可同时生成的并行化方法，代表方法是Bagging和随机森林。